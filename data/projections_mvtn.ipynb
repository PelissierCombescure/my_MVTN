{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e77689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import torch\n",
    "import ast\n",
    "import trimesh\n",
    "from tqdm import tqdm\n",
    "import open3d as o3d\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from scipy.spatial.transform import Rotation \n",
    "\n",
    "from pytorch3d.renderer import (\n",
    "    OpenGLPerspectiveCameras, look_at_view_transform,\n",
    "    RasterizationSettings, MeshRenderer, MeshRasterizer, BlendParams,\n",
    "    HardPhongShader, \n",
    "    OpenGLOrthographicCameras,\n",
    "    PointsRasterizationSettings,\n",
    "    PointsRasterizer,\n",
    "    NormWeightedCompositor, DirectionalLights)\n",
    "\n",
    "notebook_path = os.path.abspath(\"../\")\n",
    "os.chdir(notebook_path)\n",
    "from mvtorch.view_selector import MVTN\n",
    "from mvtorch.mvrenderer import MVRenderer\n",
    "from mvtorch.utils import torch_color\n",
    "from mvtorch.data import ScanObjectNN, CustomDataLoader, ModelNet40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0eb4ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_views = 12\n",
    "bs = 1\n",
    "data_dir = \"/home/mpelissi/Dataset/ModelNet40/\"\n",
    "category = \"all\"\n",
    "views_config = \"circular\"\n",
    "\n",
    "# Global parameters\n",
    "points_per_pixel=1; points_radius=0.02; image_size=224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f9b77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3D remeshing iso\n",
    "dir_remeshing =  \"/home/mpelissi/Dataset/ModelNet40_remeshing_iso\"\n",
    "dir_output = \"/home/mpelissi/MVTN/my_MVTN/outputs\"\n",
    "all_mesh_iso = glob.glob(os.path.join(dir_remeshing, \"*/*/*.obj\")); print(f\"ðŸ”Žâ€‹â€‹â€‹ Number of meshes found in {dir_remeshing} : {len(all_mesh_iso)}\"\n",
    "                                                                          )\n",
    "\n",
    "# Number of samples to load per class (for faster experimentation)\n",
    "samples_per_class_train = None  # Adjust this number as needed\n",
    "samples_per_class_test = None # Adjust this number as needed\n",
    "## Data loading\n",
    "dset_train = ModelNet40(data_dir=data_dir, split='train', samples_per_class=samples_per_class_train, category=category)\n",
    "dset_test = ModelNet40(data_dir=data_dir, split='test', samples_per_class=samples_per_class_test, category=category)\n",
    "train_loader = CustomDataLoader(dset_train, batch_size=bs, shuffle=True, drop_last=False, pin_memory=True)\n",
    "test_loader = CustomDataLoader(dset_test, batch_size=bs, shuffle=False, drop_last=False, pin_memory=True)\n",
    "print(f\"ðŸ”Žâ€‹â€‹â€‹ Which categories are used ? ðŸš¨â€‹ {category} ðŸš¨â€‹\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c388a516",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu');  print(\"ðŸ’» device : \", device)\n",
    "mvtn = MVTN(nb_views, views_config).cuda()\n",
    "mvrenderer = MVRenderer(nb_views=nb_views, return_mapping=False, pc_rendering=False).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fcf9c7",
   "metadata": {},
   "source": [
    "Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fe6ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (targets, meshes, points, names) in enumerate(train_loader):   \n",
    "    # reference mesh   \n",
    "    azim, elev, dist = mvtn(points, c_batch_size=len(targets))\n",
    "    print(\"Azimuth:\", azim, \"\\nElevation:\", elev, \"\\nDistance:\", dist)\n",
    "    rendered_images, _ = mvrenderer(meshes, points, azim=azim, elev=elev, dist=dist)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78783b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with subplots for each view\n",
    "fig, axes = plt.subplots(bs, nb_views, figsize=(20, 8))\n",
    "\n",
    "# Iterate through the batch (2 objects)\n",
    "for i in range(bs):\n",
    "    # Iterate through 6 of the 12 views for each object\n",
    "    for j in range(nb_views):\n",
    "        ax = axes[j]\n",
    "        # Get image from rendered_images and move to CPU, take first 3 channels\n",
    "        img = rendered_images[i, j].cpu().detach().permute(1, 2, 0)[:, :, :3]\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f'{os.path.basename(names[i])}\\nView {j+1}\\nAzim: {azim[i,j]:.1f}\\nElev: {elev[i,j]:.1f}\\nDist: {dist[i,j]:.1f}')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd19bb42",
   "metadata": {},
   "source": [
    "# Pour 1 obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17eedae",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_mesh_modelnet40 = names[0]; print(f\"ðŸ”Žâ€‹â€‹â€‹ Path to the reference mesh : {path_mesh_modelnet40}\")\n",
    "path_mesh_iso = [p for p in all_mesh_iso if os.path.basename(path_mesh_modelnet40).split('_SM')[0] in p][0]\n",
    "cat = path_mesh_iso.split('/')[-3]; type = path_mesh_iso.split('/')[-2]; name = path_mesh_iso.split('/')[-1].split('.')[0]\n",
    "print(cat, type, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1dde84",
   "metadata": {},
   "source": [
    "Alignement OBJ et PLY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce010525",
   "metadata": {},
   "source": [
    "Projections dans les N vues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6a8380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depthmaps\n",
    "rendered_images, cameras, new_meshes, meshes, R, T = my_render_meshes(mesh_init, None, azims, elevs, dists, light)\n",
    "# transform xyz to the camera view coordinates\n",
    "cam_points = cameras.get_world_to_view_transform().transform_points(world_points)\n",
    "cam_points_np = cam_points.cpu().numpy()\n",
    "# transform xyz to the camera view coordinates\n",
    "cam_normals = cameras.get_world_to_view_transform().transform_normals(world_normals)\n",
    "cam_normals_np = cam_normals.cpu().numpy()\n",
    "# Cartes de profondeur\n",
    "depthmaps_np = fragments.zbuf[:,:,:,0].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a85f14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming depthmap_i is generated for each view in the loop from cell 13\n",
    "fig, axes = plt.subplots(views//6, 6, figsize=(20, 6))\n",
    "fig.suptitle(\"My Depth Images \"+name, fontsize=16)\n",
    "\n",
    "for i in range(views):\n",
    "    row, col = divmod(i, 6)    \n",
    "    axes[row, col].imshow(depthmaps_np[i], cmap='viridis')\n",
    "    axes[row, col].set_title(f\"View {i+1} {c_views_azim[0,i]} {c_views_elev[0,i]} {c_views_dist[0,i]}\")\n",
    "    cbar = fig.colorbar(plt.cm.ScalarMappable(cmap='viridis'), ax=axes[row, col], orientation='vertical', fraction=0.046, pad=0.04)\n",
    "    cbar.set_label('Depth Value')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31555d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pix_to_face is of shape (N, H, W, 1)\n",
    "pix_to_face = fragments.pix_to_face ; print(\"pix_to_face shape:\", pix_to_face.shape)  # Expected: [N, H, W, 1]\n",
    "pix_to_face = fragments.pix_to_face[..., 0] ; print(\"pix_to_face shape:\", pix_to_face.shape)  # Expected: [N, H, W]\n",
    "print(\"pix_to_face shape:\", pix_to_face.shape)  # Expected: [N, H, W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530db5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "visible_faces_per_view = []\n",
    "visible_verts_per_view = []\n",
    "#faces = world_mesh.faces_packed()  # (F, 3)\n",
    "\n",
    "for b in tqdm(range(pix_to_face.shape[0])):\n",
    "    array_pt_cloud_b = cam_points_np[b]\n",
    "    array_normals_b = cam_normals_np[b]\n",
    "    \n",
    "    # 1. Get valid face indices (ignore -1 = background)\n",
    "    face_ids = pix_to_face[b]\n",
    "    idx_visible_faces_b = torch.unique(face_ids[face_ids >= 0]) % nb_faces  # remove -1 (background)\n",
    "    idx_visible_faces_b_np = idx_visible_faces_b.cpu().numpy()\n",
    "    visible_faces_per_view.append(idx_visible_faces_b)\n",
    "    print(f\"Visible faces for view {b}: {idx_visible_faces_b.shape}\")  \n",
    "    \n",
    "    # 2. Extract visible vertices from those faces\n",
    "    idx_visible_verts_b = torch.unique(torch.tensor(array_faces)[idx_visible_faces_b])\n",
    "    idx_visible_verts_b_np = idx_visible_verts_b.cpu().numpy()\n",
    "    visible_verts_per_view.append(idx_visible_verts_b)   \n",
    "    print(f\"Visible vertices for view {b}: {idx_visible_verts_b.shape}\") \n",
    "    \n",
    "    obj_filename = f\"{os.path.join(dir_output, name)}_myview_{b+1}_color.obj\"\n",
    "    write_obj_with_color(array_pt_cloud_b, array_faces, idx_visible_verts_b_np, obj_filename)\n",
    "    \n",
    "    ## Angle sommets visibles\n",
    "    cos_angle_visible_vertex_b = np.full(array_pt_cloud_b.shape[0], np.nan)\n",
    "    # sommets et normales visibles\n",
    "    v_visible = array_pt_cloud_b[idx_visible_verts_b_np]\n",
    "    n_visible = array_normals_b[idx_visible_verts_b_np]\n",
    "    n_norms = np.linalg.norm(n_visible, axis=1, keepdims=True)\n",
    "    n_norms[np.where(n_norms == 0)] = 1e-10 # quelques normales sont nulles\n",
    "    # normalisation\n",
    "    n_visible_norm = n_visible / n_norms\n",
    "    # vecteurs directeurs\n",
    "    D = -v_visible\n",
    "    D /= np.linalg.norm(D, axis=1, keepdims=True)\n",
    "    cos_alpha = np.abs(np.sum(D * n_visible_norm, axis=1))\n",
    "    cos_angle_visible_vertex_b[idx_visible_verts_b_np] = cos_alpha   \n",
    "    obj_filename_angle = f\"{os.path.join(dir_output, name)}_myview_{b+1}_angles.obj\"\n",
    "    save_colored_obj_with_faces(obj_filename_angle, array_pt_cloud_b, cos_angle_visible_vertex_b, array_faces)\n",
    "    \n",
    "    \n",
    "    # Surface Totale 3D\n",
    "    surface3D_b = np.sum(calculer_aires_triangles_batch(array_pt_cloud_b, array_faces))\n",
    "    # Surface visible de la projection courante\n",
    "    surface3D_visible_b = np.sum(calculer_aires_triangles_batch(array_pt_cloud_b, array_faces[idx_visible_faces_b_np]))\n",
    "    \n",
    "    #data_output_path = os.path.join(dir_output, cat, type, name+\"_cam\"+str(i+1)+\"_data.npz\")\n",
    "    data_output_path = os.path.join(dir_output, name+\"_cam\"+str(b+1)+\"_data.npz\")\n",
    "\n",
    "    # Step 1: Save all array data in a compressed .npz file\n",
    "    # np.savez_compressed(\n",
    "    #     data_output_path,\n",
    "    #     array_pt_cloud = array_pt_cloud_b,\n",
    "    #     array_normals = array_normal_b,\n",
    "    #     dephtmap = depthmaps_np[b],\n",
    "    #     visible_vertex_idx = idx_visible_verts_b_np,\n",
    "    #     visible_faces = idx_visible_faces_b_np,\n",
    "    #     cos_angles = cos_angle_visible_vertex_b,\n",
    "    #     surface3D = surface3D_b,\n",
    "    #     surface3D_visible = surface3D_visible_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2669dc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(idx_visible_faces_b_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03987c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clip2point",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
