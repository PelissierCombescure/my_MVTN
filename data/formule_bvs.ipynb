{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conda `clip2point`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import tqdm \n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A changer !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input directory: /media/disk1/mpelissi-data/MVTN/circular-12/Projections\n",
      "Output directory: /media/disk1/mpelissi-data/MVTN/circular-12/BVS\n"
     ]
    }
   ],
   "source": [
    "# nb vue\n",
    "nb_view = 12\n",
    "view_config = \"circular\"\n",
    "\n",
    "# Data sur les projections\n",
    "dir_projection = f\"/media/disk1/mpelissi-data/MVTN/{view_config}-{nb_view}/Projections\"\n",
    "# Output\n",
    "dir_output = f\"/media/disk1/mpelissi-data/MVTN/{view_config}-{nb_view}/BVS\"\n",
    "print(f\"Input directory: {dir_projection}\")\n",
    "print(f\"Output directory: {dir_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of saillance files: 12288\n",
      "ðŸ”Žâ€‹â€‹â€‹ Parmi les 12311 mesh :\n",
      "On a les projections des 12 vues circular de 12301 mesh\n",
      "Parmi ces 12301 mesh, on a les saillances de 12280 mesh\n"
     ]
    }
   ],
   "source": [
    "# Model 3D remeshing iso\n",
    "dir_remeshing = \"/home/mpelissi/Dataset/ModelNet40_remeshing_iso\"\n",
    "paths_iso = glob.glob(os.path.join(dir_remeshing, \"*/*/*.obj\")); \n",
    "paths_projection = glob.glob(os.path.join(dir_projection, \"*/*/*cam1_data.npz\"))\n",
    "\n",
    "dir_saillance = \"/media/disk1/mpelissi-data/Modelnet40_limper_remeshing_iso_lce\"\n",
    "paths_limper = glob.glob(os.path.join(dir_saillance, \"*/*/*.csv\")); print(f\"Number of saillance files: {len(paths_limper)}\")\n",
    "print(f\"ðŸ”Žâ€‹â€‹â€‹ Parmi les {len(paths_iso)} mesh :\\nOn a les projections des {nb_view} vues {view_config} de {len(paths_projection)} mesh\")\n",
    "\n",
    "names_limper = [os.path.basename(path).split(\"_lce\")[0] for path in paths_limper]\n",
    "names_projection = [os.path.basename(path).split(\"_cam1_data.npz\")[0] for path in paths_projection]\n",
    "names_commun = list(set(names_limper) & set(names_projection))\n",
    "print(f\"Parmi ces {len(paths_projection)} mesh, on a les saillances de {len(names_commun)} mesh\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_NAN = []\n",
    "seuil_NAN = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 78.61it/s]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for path_limper in tqdm.tqdm(paths_limper[:1]):\n",
    "    name = os.path.basename(path_limper).split('_lce')[0]    \n",
    "    try:\n",
    "        #if True:\n",
    "        # Informations sur le mesh\n",
    "        cat = path_limper.split('/')[-3]; type = path_limper.split('/')[-2]\n",
    "        if not os.path.exists(os.path.join(dir_output, cat, type, name+\"_bvs.pkl\")):\n",
    "            # Saillance limper associÃ©e\n",
    "            df_saillance_limper = pd.read_csv(path_limper, header=None)\n",
    "            # colonne Combined_Saliency_Norm\n",
    "            saillance_limper = np.array([float(s) for s in list(df_saillance_limper[1])[1:]])\n",
    "            ## les valeurs des saillances sont dÃ©jÃ  normalisÃ©es entre 0 et 1\n",
    "\n",
    "            dict_scores = {}\n",
    "            contain_nan = False\n",
    "            # Pour chaque pov\n",
    "            for i in range(0, nb_view): \n",
    "                #print(k)\n",
    "                # data du pov k\n",
    "                path_npz_cam_i = os.path.join(dir_projection, cat, type, name+\"_cam\"+str(i+1)+\"_data.npz\")\n",
    "                # Load the .npz file and pkl file\n",
    "                data_cam_i = np.load(path_npz_cam_i)\n",
    "                # sommets visibles\n",
    "                sommets_visible = data_cam_i['visible_vertex_idx']#; print(len(sommets_visible))\n",
    "                #mask_sommets_visible = data_cam_i['visible_vertex_bin']\n",
    "                cos_angles = data_cam_i['cos_angles']\n",
    "                # Somme [limper*angle]\n",
    "                saillance_limper_visible = saillance_limper[sommets_visible]\n",
    "                if np.isnan(saillance_limper_visible).any() : contain_nan = True\n",
    "                terme_somme_saillance = np.sum(saillance_limper_visible*cos_angles[sommets_visible])\n",
    "                if len(np.where(np.isnan(cos_angles[sommets_visible]))[0])>0: print(i+1, name)\n",
    "                # Surface 3D + 'normalisation' : on divise par la surface 3D totale de l'objet\n",
    "                terme_surface3d = data_cam_i['surface3D_visible']/data_cam_i['surface3D']\n",
    "                \n",
    "                # Sauvegardes des termes\n",
    "                dict_scores['cam_'+str(i+1)] = {'terme_surface3d': terme_surface3d, 'saillance': terme_somme_saillance}\n",
    "                \n",
    "                taux_nan = len(np.where(np.isnan(saillance_limper_visible))[0])/len(saillance_limper_visible)\n",
    "                if taux_nan > seuil_NAN:\n",
    "                    contain_nan = True\n",
    "                    paths_NAN.append((path_limper, taux_nan))\n",
    "                    break\n",
    "            \n",
    "            if not contain_nan:\n",
    "                # Normalisation du terme de saillance pour les nb_view povs\n",
    "                max_terme_saillance = np.max([dict_scores['cam_'+str(i+1)]['saillance'] for i in range(0, nb_view)])\n",
    "                dict_scores = {k: {'terme_surface3d': v['terme_surface3d'], 'saillance': v['saillance'], \n",
    "                                    'terme_saillance': v['saillance']/max_terme_saillance} for k, v in dict_scores.items()}\n",
    "\n",
    "                # Scores = (surface3D + saillance) pour les nb_view povs\n",
    "                for k, v in dict_scores.items():\n",
    "                    dict_scores[k]['score'] =  v['terme_surface3d'] + v['terme_saillance']\n",
    "                    \n",
    "                # Normalisation des score --> / par la somme des scores\n",
    "                sum_scores = np.sum([dict_scores[k]['score'] for k in dict_scores.keys()])\n",
    "                for k, v in dict_scores.items():\n",
    "                    dict_scores[k]['score_norm'] =  v['score']/sum_scores\n",
    "                    \n",
    "                # BVS \n",
    "                score_max = np.max([dict_scores[k]['score'] for k in dict_scores.keys()])\n",
    "                dict_scores['bvs'] = [k for k in dict_scores.keys() if dict_scores[k]['score'] == score_max][0]\n",
    "\n",
    "                # si plusieurs \n",
    "                if len([k for k in dict_scores.keys() if (('cam' in k) and (dict_scores[k]['score'] == score_max))]) > 1: print(\"Plusieurs pov\", name)\n",
    "\n",
    "                metadata = {\n",
    "                    \"name_limper\": path_limper, \"categorie\": cat, \"type\": type, \"name\": name,\n",
    "                    \"bvs\" : dict_scores['bvs'], \"score_max\": score_max, \"score_max_norm\": dict_scores[dict_scores['bvs']]['score_norm'], \n",
    "                    \"scores\": dict_scores}\n",
    "\n",
    "                with open(os.path.join(dir_output, cat, type, name+\"_bvs.pkl\"), \"wb\") as f: pickle.dump(metadata, f)\n",
    "                print(\"Enregistrement de\", os.path.join(dir_output, cat, type, name+\"_bvs.pkl\"))\n",
    "            \n",
    "                #Ajout du rÃ©sultat\n",
    "                results.append(('ok', path_limper, \"RAS\", contain_nan))\n",
    "            else:\n",
    "                results.append(('nan', path_limper, \"Contient des NaN\", contain_nan))\n",
    "        else :\n",
    "            results.append((\"skip\", path_limper, \"DÃ©jÃ  traitÃ©\", False))         \n",
    "    except Exception as e:\n",
    "        #print(e)\n",
    "        results.append((\"pbl\",path_limper, e, contain_nan)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('/home/mpelissi/MVTN/my_MVTN/data/error', \"results_bvs.txt\"), \"w\") as f:\n",
    "    for p in paths_NAN:\n",
    "        f.write(f\"{p[0]} - Taux de NaN : {p[1]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write results to file\n",
    "# List all files in thee current directory\n",
    "files_in_directory = os.listdir('/home/mpelissi/MVTN/my_MVTN/data/error')\n",
    "# Filter files containing the word 'error'\n",
    "nb_error_files = len([file for file in files_in_directory if (('error' in file) and ('bvs' in file))])\n",
    "if nb_error_files >= 0: \n",
    "    file_name = os.path.join('/home/mpelissi/MVTN/my_MVTN/data/error', f\"error_bvs_run{nb_error_files+1}_{view_config}_{nb_view}.txt\")\n",
    "    \n",
    "with open(file_name, \"w\") as file:\n",
    "    file.write(\"Date: {:%Y-%m-%d %H:%M:%S} - Error during saving\\n\".format(datetime.now()))\n",
    "    for verdict, name, err, bool_nan in results:\n",
    "       file.write(f\"{verdict}: {name} : {err} -- NAN ? : {bool_nan}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MVTN_env3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
