{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e77689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import torch\n",
    "import ast\n",
    "import trimesh\n",
    "from tqdm import tqdm\n",
    "import open3d as o3d\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from scipy.spatial.transform import Rotation \n",
    "\n",
    "notebook_path = os.path.abspath(\"../\")\n",
    "os.chdir(notebook_path)\n",
    "from mvtorch.view_selector import MVTN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9a0cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the absolute path of MYPOINTCLIP (two levels up)\n",
    "root_dir = os.path.abspath(\"/home/mpelissi/CLIP/myCLIP2Point/\")\n",
    "from functions_pov_clip2pt import *\n",
    "print(\"Root directory:\", root_dir)\n",
    "\n",
    "from render.selector import Selector\n",
    "from render.render import *\n",
    "from utils_clip2point import read_state_dict, read_ply, create_rotation_matrix, pcshow, write_obj_with_color, calculer_aires_triangles_batch, save_colored_obj_with_faces, read_paths_from_txt\n",
    "\n",
    "# Model 3D remeshing iso\n",
    "dir_remeshing =  \"/home/mpelissi/Dataset/ModelNet40_remeshing_iso\"\n",
    "dir_output = \"/home/mpelissi/MVTN/my_MVTN/outputs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c388a516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global parameters\n",
    "nb_views = 12; views_config = 'circular'\n",
    "points_per_pixel=1; points_radius=0.02; image_size=224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae570b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu');  print(\"ðŸ’» device : \", device)\n",
    "mvtn = MVTN(nb_views, views_config).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd19bb42",
   "metadata": {},
   "source": [
    "# Pour 1 obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17eedae",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ply = \"10_03.ply\"\n",
    "path_obj = correspondence_df[correspondence_df['path_ply'] == path_ply]['path_obj'].values[0]\n",
    "print(\"ply:\", path_ply)\n",
    "print(\"obj:\", path_obj)\n",
    "cat = path_obj.split('/')[-3]; type = path_obj.split('/')[-2]; name = path_obj.split('/')[-1].split('_SM')[0]\n",
    "print(cat, type, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8aac9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_obj.split('/')[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1dde84",
   "metadata": {},
   "source": [
    "Alignement OBJ et PLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea768d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## RÃ©cupÃ©ration des coordonnÃ©es des sommets, des faces et des normales\n",
    "mesh_init = trimesh.load_mesh(os.path.join(dir_remeshing, path_obj+\".obj\"))\n",
    "# Save point cloud to .ply file\n",
    "view_pcd_init = o3d.geometry.PointCloud(); view_pcd_init.points = o3d.utility.Vector3dVector(np.array(mesh_init.vertices))\n",
    "# Save the point cloud to a .ply file\n",
    "o3d.io.write_point_cloud(f\"{os.path.join(dir_output, name)}_myview_init_v2.ply\", view_pcd_init)\n",
    "## Rotation pour aligner avec les PLY-limper\n",
    "rotation_to_apply = ast.literal_eval(rotations[rotations['path_ply'] == path_ply]['transformation'].values[0])\n",
    "\n",
    "mesh_aligned = mesh_init.copy()\n",
    "for transf in rotation_to_apply:\n",
    "    angle = transf[1]\n",
    "    matrix = create_rotation_matrix('Z', angle)    \n",
    "    mesh_aligned.apply_transform(matrix)\n",
    "    \n",
    "## RÃ©cupÃ©ration des coordonnÃ©es des sommets, des faces et des normales\n",
    "array_coords_aligned = np.array(mesh_aligned.vertices); nb_vertices = len(array_coords_aligned)\n",
    "print(\"nb vertices aligned : \", nb_vertices)\n",
    "array_normals_aligned = np.array(mesh_aligned.vertex_normals)\n",
    "array_faces = np.array(mesh_aligned.faces); nb_faces = len(array_faces)\n",
    "print(\"nb faces aligned : \", nb_faces)\n",
    "\n",
    "## Save point cloud to .ply file\n",
    "view_pcd_aligned = o3d.geometry.PointCloud()\n",
    "view_pcd_aligned.points = o3d.utility.Vector3dVector(array_coords_aligned)\n",
    "view_pcd_aligned.normals = o3d.utility.Vector3dVector(array_normals_aligned)\n",
    "# Save the point cloud to a .ply file\n",
    "output_file = f\"{os.path.join(dir_output, name)}_myview_init_aligned_v2-normals.ply\"\n",
    "o3d.io.write_point_cloud(output_file, view_pcd_aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218f5472",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32fecfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert to a NumPy array and take only XYZ coordinates\n",
    "points_aligned = torch.tensor(array_coords_aligned, dtype=torch.float32).cuda()\n",
    "normals_aligned = torch.tensor(array_normals_aligned, dtype=torch.float32).cuda()\n",
    "print(\"points_aligned shape:\", points_aligned.shape)  # Expected: [N, 3]\n",
    "print(\"normals_aligned shape:\", normals_aligned.shape)  # Expected: [N, 3]\n",
    "\n",
    "# Ensure the point cloud has the correct shape [B, N, 3]\n",
    "B = 1  # Batch size\n",
    "points_aligned = points_aligned.unsqueeze(0)  # Add batch dimension -> [1, N, 3]\n",
    "normals_aligned = normals_aligned.unsqueeze(0)  # Add batch dimension -> [1, N, 3]\n",
    "print(\"\\npoints_aligned shape:\", points_aligned.shape)  # Expected: [1, N, 3]\n",
    "print(\"normals_aligned shape:\", points_aligned.shape)  # Expected: [1, N, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce010525",
   "metadata": {},
   "source": [
    "Projections dans les 6 vues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bc19cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cameras positions\n",
    "c_views_azim, c_views_elev, c_views_dist = selector(points_aligned)\n",
    "print(points_aligned.shape[0])\n",
    "print(c_views_azim.shape, c_views_elev.shape, c_views_dist.shape)  # Expected: [1, 12]\n",
    "print(c_views_elev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6a8380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depthmaps\n",
    "fragments, world_points, cameras, world_mesh, world_normals, Rs, Ts = my_render_mesh(points_aligned, normals_aligned, array_faces, c_views_azim, c_views_elev, c_views_dist, views, image_size, device)\n",
    "# transform xyz to the camera view coordinates\n",
    "cam_points = cameras.get_world_to_view_transform().transform_points(world_points)\n",
    "cam_points_np = cam_points.cpu().numpy()\n",
    "# transform xyz to the camera view coordinates\n",
    "cam_normals = cameras.get_world_to_view_transform().transform_normals(world_normals)\n",
    "cam_normals_np = cam_normals.cpu().numpy()\n",
    "# Cartes de profondeur\n",
    "depthmaps_np = fragments.zbuf[:,:,:,0].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a85f14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming depthmap_i is generated for each view in the loop from cell 13\n",
    "fig, axes = plt.subplots(views//6, 6, figsize=(20, 6))\n",
    "fig.suptitle(\"My Depth Images \"+name, fontsize=16)\n",
    "\n",
    "for i in range(views):\n",
    "    row, col = divmod(i, 6)    \n",
    "    axes[row, col].imshow(depthmaps_np[i], cmap='viridis')\n",
    "    axes[row, col].set_title(f\"View {i+1} {c_views_azim[0,i]} {c_views_elev[0,i]} {c_views_dist[0,i]}\")\n",
    "    cbar = fig.colorbar(plt.cm.ScalarMappable(cmap='viridis'), ax=axes[row, col], orientation='vertical', fraction=0.046, pad=0.04)\n",
    "    cbar.set_label('Depth Value')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31555d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pix_to_face is of shape (N, H, W, 1)\n",
    "pix_to_face = fragments.pix_to_face ; print(\"pix_to_face shape:\", pix_to_face.shape)  # Expected: [N, H, W, 1]\n",
    "pix_to_face = fragments.pix_to_face[..., 0] ; print(\"pix_to_face shape:\", pix_to_face.shape)  # Expected: [N, H, W]\n",
    "print(\"pix_to_face shape:\", pix_to_face.shape)  # Expected: [N, H, W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530db5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "visible_faces_per_view = []\n",
    "visible_verts_per_view = []\n",
    "#faces = world_mesh.faces_packed()  # (F, 3)\n",
    "\n",
    "for b in tqdm(range(pix_to_face.shape[0])):\n",
    "    array_pt_cloud_b = cam_points_np[b]\n",
    "    array_normals_b = cam_normals_np[b]\n",
    "    \n",
    "    # 1. Get valid face indices (ignore -1 = background)\n",
    "    face_ids = pix_to_face[b]\n",
    "    idx_visible_faces_b = torch.unique(face_ids[face_ids >= 0]) % nb_faces  # remove -1 (background)\n",
    "    idx_visible_faces_b_np = idx_visible_faces_b.cpu().numpy()\n",
    "    visible_faces_per_view.append(idx_visible_faces_b)\n",
    "    print(f\"Visible faces for view {b}: {idx_visible_faces_b.shape}\")  \n",
    "    \n",
    "    # 2. Extract visible vertices from those faces\n",
    "    idx_visible_verts_b = torch.unique(torch.tensor(array_faces)[idx_visible_faces_b])\n",
    "    idx_visible_verts_b_np = idx_visible_verts_b.cpu().numpy()\n",
    "    visible_verts_per_view.append(idx_visible_verts_b)   \n",
    "    print(f\"Visible vertices for view {b}: {idx_visible_verts_b.shape}\") \n",
    "    \n",
    "    obj_filename = f\"{os.path.join(dir_output, name)}_myview_{b+1}_color.obj\"\n",
    "    write_obj_with_color(array_pt_cloud_b, array_faces, idx_visible_verts_b_np, obj_filename)\n",
    "    \n",
    "    ## Angle sommets visibles\n",
    "    cos_angle_visible_vertex_b = np.full(array_pt_cloud_b.shape[0], np.nan)\n",
    "    # sommets et normales visibles\n",
    "    v_visible = array_pt_cloud_b[idx_visible_verts_b_np]\n",
    "    n_visible = array_normals_b[idx_visible_verts_b_np]\n",
    "    n_norms = np.linalg.norm(n_visible, axis=1, keepdims=True)\n",
    "    n_norms[np.where(n_norms == 0)] = 1e-10 # quelques normales sont nulles\n",
    "    # normalisation\n",
    "    n_visible_norm = n_visible / n_norms\n",
    "    # vecteurs directeurs\n",
    "    D = -v_visible\n",
    "    D /= np.linalg.norm(D, axis=1, keepdims=True)\n",
    "    cos_alpha = np.abs(np.sum(D * n_visible_norm, axis=1))\n",
    "    cos_angle_visible_vertex_b[idx_visible_verts_b_np] = cos_alpha   \n",
    "    obj_filename_angle = f\"{os.path.join(dir_output, name)}_myview_{b+1}_angles.obj\"\n",
    "    save_colored_obj_with_faces(obj_filename_angle, array_pt_cloud_b, cos_angle_visible_vertex_b, array_faces)\n",
    "    \n",
    "    \n",
    "    # Surface Totale 3D\n",
    "    surface3D_b = np.sum(calculer_aires_triangles_batch(array_pt_cloud_b, array_faces))\n",
    "    # Surface visible de la projection courante\n",
    "    surface3D_visible_b = np.sum(calculer_aires_triangles_batch(array_pt_cloud_b, array_faces[idx_visible_faces_b_np]))\n",
    "    \n",
    "    #data_output_path = os.path.join(dir_output, cat, type, name+\"_cam\"+str(i+1)+\"_data.npz\")\n",
    "    data_output_path = os.path.join(dir_output, name+\"_cam\"+str(b+1)+\"_data.npz\")\n",
    "\n",
    "    # Step 1: Save all array data in a compressed .npz file\n",
    "    # np.savez_compressed(\n",
    "    #     data_output_path,\n",
    "    #     array_pt_cloud = array_pt_cloud_b,\n",
    "    #     array_normals = array_normal_b,\n",
    "    #     dephtmap = depthmaps_np[b],\n",
    "    #     visible_vertex_idx = idx_visible_verts_b_np,\n",
    "    #     visible_faces = idx_visible_faces_b_np,\n",
    "    #     cos_angles = cos_angle_visible_vertex_b,\n",
    "    #     surface3D = surface3D_b,\n",
    "    #     surface3D_visible = surface3D_visible_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2669dc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(idx_visible_faces_b_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03987c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clip2point",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
