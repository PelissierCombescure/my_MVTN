import sys
import os
import tqdm
import time 
import json
import matplotlib.pyplot as plt
from datetime import datetime
import subprocess

os.environ["CUDA_VISIBLE_DEVICES"] = "0"

import torch
print(torch.cuda.is_available())
from mvtorch.data import ScanObjectNN, CustomDataLoader, ModelNet40
from mvtorch.networks import MVNetwork
from mvtorch.view_selector import MVTN
from mvtorch.mvrenderer import MVRenderer

from utils import *


# Run the command and capture the output
current_dir = subprocess.check_output('pwd', shell=True).decode('utf-8').strip()
Papier_inter3_dir = os.path.abspath(os.path.join(current_dir, "../../"))

path_to_Dataset = Papier_inter3_dir+"/Dataset/"
results_dir = current_dir+"/results"

data_dir= path_to_Dataset+'ModelNet40'#+'ScanObjectNN' # specifiy where did you put the data rel
nb_views = 12 # Number of views generated by view selector
epochs = 100

## Data loading
dset_train = ModelNet40(data_dir=data_dir, split='train')
dset_test = ModelNet40(data_dir=data_dir, split='test')

train_loader = CustomDataLoader(dset_train, batch_size=20, shuffle=True, drop_last=False)
test_loader = CustomDataLoader(dset_test, batch_size=20, shuffle=False, drop_last=False)

## Network initialization
import os
os.environ["CUDA_VISIBLE_DEVICES"] = "0"
# Create backbone multi-view network (ResNet18)
mvnetwork = MVNetwork(num_classes=len(dset_train.classes), num_parts=None, mode='cls', net_name='resnet18').cuda()

# Create backbone optimizer
optimizer = torch.optim.AdamW(mvnetwork.parameters(), lr=0.00001, weight_decay=0.03)

# Create view selector
mvtn = MVTN(nb_views=nb_views).cuda()

# Create optimizer for view selector (In case views are not fixed, otherwise set to None)
#mvtn_optimizer = torch.optim.AdamW(mvtn.parameters(), lr=0.0001, weight_decay=0.01)
mvtn_optimizer = None

# Create multi-view renderer
mvrenderer = MVRenderer(nb_views=nb_views, return_mapping=False)

# Create loss function for training
criterion = torch.nn.CrossEntropyLoss()

## Training
# Create a directory with the current date and time
current_time = datetime.now().strftime("%m-%d_%Hh%Mm%S")
results_dir_current = results_dir+f'results_{current_time}'
os.makedirs(results_dir_current, exist_ok=True)
os.makedirs(results_dir_current+"/best", exist_ok=True)
os.makedirs(results_dir_current+"/by_epoch", exist_ok=True)

# Variables to track the best accuracy
best_accuracy = 0.0
best_epoch = 0

# Lists to store loss and accuracy for plotting
train_losses = []
train_accuracies = []
test_losses = []
test_accuracies = []

# Dictionary to store training parameters and results
training_info = {
    'epochs': epochs,
    'learning_rate': 0.00001,
    'weight_decay': 0.03,
    'batch_size': None,  # You can set this based on your train_loader
    'train_losses': [],
    'train_accuracies': [],
    'test_losses':[],
    'test_accuracies': [],
    'best_accuracy': best_accuracy,
    'best_epoch': best_epoch
}

###############################################################################################
for epoch in range(epochs):
    #print(f"\nEpoch {epoch + 1}/{epochs}")
    #print("\nTraining...")
    
    running_loss = 0
    correct = 0.0
    
    mvnetwork.train(); mvtn.train(); mvrenderer.train()    
    
    # Use tqdm to create a progress bar
    with tqdm.tqdm(total=len(train_loader), desc=f'Training Epoch {epoch + 1}/{epochs}', unit='batch') as pbar:
        for i, (targets, meshes, points) in tqdm.tqdm(enumerate(train_loader)):        
            azim, elev, dist = mvtn(points, c_batch_size=len(targets))
            rendered_images, _ = mvrenderer(meshes, points, azim=azim, elev=elev, dist=dist)
            outputs = mvnetwork(rendered_images)[0]

            loss = criterion(outputs, targets.cuda())
            running_loss += loss.item()
            loss.backward()
            correct += (torch.max(outputs, dim=1)[1] == targets.cuda()).to(torch.int32).sum().item()
            
            optimizer.step()
            optimizer.zero_grad()
            
            if mvtn_optimizer is not None:
                mvtn_optimizer.step()
                mvtn_optimizer.zero_grad()

            # Update tqdm progress bar
            #pbar.set_postfix({'loss': running_loss / (i + 1), 'accuracy': 100.0 * correct / ((i + 1) * len(targets))})
            pbar.update(1)  # Increment progress bar
    
    avg_train_loss = running_loss / len(train_loader)
    avg_train_accuracy = 100.0 * correct / len(dset_train)
    train_losses.append(avg_train_loss)
    train_accuracies.append(avg_train_accuracy)
        
    #print(f"\nAverage Training Loss = {(running_loss / len(train_loader)):.5f}. Average Training Accuracy = {(100.0*correct / len(dset_train)):.2f}.")
    pbar.set_postfix({'loss': running_loss / len(train_loader), 'accuracy': 100.0*correct / len(dset_train)})
    
    ############################################
    # Validate after each epoch
    #print("\nTesting...")
    mvnetwork.eval(); mvtn.eval(); mvrenderer.eval()
    running_loss = 0
    correct = 0.0
    # Use tqdm to create a progress bar
    with tqdm.tqdm(total=len(train_loader), desc=f'Testing Epoch {epoch + 1}/{epochs}', unit='batch') as pbar:
        for i, (targets, meshes, points) in enumerate(test_loader):
            with torch.no_grad():
                azim, elev, dist = mvtn(points, c_batch_size=len(targets))
                rendered_images, _ = mvrenderer(meshes, points, azim=azim, elev=elev, dist=dist)
                outputs = mvnetwork(rendered_images)[0]
                
                loss = criterion(outputs, targets.cuda())
                running_loss += loss.item()
                correct += (torch.max(outputs, dim=1)[1] == targets.cuda()).to(torch.int32).sum().item()

                # Update tqdm progress bar
                #pbar.set_postfix({'loss': running_loss / (i + 1), 'accuracy': 100.0 * correct / ((i + 1) * len(targets))})
                pbar.update(1)  # Increment progress bar
    
    avg_test_loss = running_loss / len(test_loader)
    avg_test_accuracy = 100.0 * correct / len(dset_test)
    test_losses.append(avg_test_loss)
    test_accuracies.append(avg_test_accuracy)
    
    #print(f"\nTotal Average Test Loss = {(running_loss / len(test_loader)):.5f}.  Average Test Accuracy = {(100.0*correct / len(dset_test)):.2f}.")
    pbar.set_postfix({'loss': running_loss / len(test_loader), 'accuracy': 100.0*correct / len(dset_test)})
    
    ############################################
    #print("\Saving...")
    if True:
        # Save the weights after each epoch
        torch.save(mvnetwork.state_dict(), results_dir_current+f'/by_epoch/mvnetwork_epoch_{epoch + 1}.pth')
        torch.save(mvtn.state_dict(), results_dir_current+f'/by_epoch/mvtn_epoch_{epoch + 1}.pth')
        torch.save(mvrenderer.state_dict(), results_dir_current+f'/by_epoch/mvrenderer_epoch_{epoch + 1}.pth')
        
        # Save the weights if the current epoch's accuracy is better than the best accuracy
        test_accuracy = 100.0 * correct / len(dset_test)
        if test_accuracy > best_accuracy:
            best_accuracy = test_accuracy
            best_epoch = epoch + 1  # Store the best epoch (1-indexed)
            
            # Save the weights of the best epoch
            torch.save(mvnetwork.state_dict(), results_dir_current+f'/best/mvnetwork_best_{epoch+1}.pth')
            torch.save(mvtn.state_dict(), results_dir_current+f'/best/mvtn_best_{epoch+1}.pth')
            torch.save(mvrenderer.state_dict(), results_dir_current+f'/best/mvrenderer_best_{epoch+1}.pth')
            print(f"Best epoch saved : {epoch+1}, with accuracy: {best_accuracy:.2f}%")
            
        # Update training_info with the latest epoch results
        training_info['train_losses'].append(avg_train_loss)
        training_info['train_accuracies'].append(avg_train_accuracy)
        training_info['test_losses'].append(avg_test_loss)
        training_info['test_accuracies'].append(avg_test_accuracy)
        training_info['best_accuracy'] = best_accuracy
        training_info['best_epoch'] = best_epoch

###############################################################################################
# Save training information to a JSON file
with open(results_dir_current+'/training_info.json', 'w') as json_file:
    json.dump(training_info, json_file, indent=4)

print("Training complete! Best epoch:", best_epoch)

# Save the training information with 2 figure
save_loss_acc(results_dir_current,train_losses, test_losses, train_accuracies, test_accuracies)