{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [MVTorch](https://github.com/ajhamdi/mvtorch) 3D Calssification Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- download common 3D datasets ([ModelNet40](https://mega.nz/file/mm5FhJ7I#jGECWn-QSCLH9LLoxhZzSWnf9LCtCavV12toj9SJKPM), [ScanObjectNN](https://mega.nz/file/ampg2QyT#Exo22r-8jzgCa2MOqoqipd39HVqYKG5iykJ5bovjsuI)) and unzip inside `data` directory.\n",
    "\n",
    "- Conda env : `mvtorchenv1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: ligne 1 : cd: data/: Aucun fichier ou dossier de ce nom\n"
     ]
    }
   ],
   "source": [
    "!cd .. && cd .. && cd data/ \n",
    "# # download ModelNet40 from https://mega.nz/file/mm5FhJ7I#jGECWn-QSCLH9LLoxhZzSWnf9LCtCavV12toj9SJKPM \n",
    "# # download ScanObjectNN from https://mega.nz/file/ampg2QyT#Exo22r-8jzgCa2MOqoqipd39HVqYKG5iykJ5bovjsuI \n",
    "\n",
    "# sudo rmmod nvidia_uvm\n",
    "# sudo modprobe nvidia_uvm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depenenancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pelissier/miniforge3/envs/mvtorchenv1/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import tqdm\n",
    "import time \n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import subprocess\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "from mvtorch.data import ScanObjectNN, CustomDataLoader, ModelNet40\n",
    "from mvtorch.networks import MVNetwork\n",
    "from mvtorch.view_selector import MVTN\n",
    "from mvtorch.mvrenderer import MVRenderer\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the command and capture the output\n",
    "current_dir = subprocess.check_output('pwd', shell=True).decode('utf-8').strip()\n",
    "Papier_inter3_dir = os.path.abspath(os.path.join(current_dir, \"../../\"))\n",
    "\n",
    "path_to_Dataset = Papier_inter3_dir+\"/Dataset/\"\n",
    "results_dir = current_dir+\"/results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir= path_to_Dataset+'ModelNet40'#+'ScanObjectNN' # specifiy where did you put the data rel\n",
    "nb_views = 8 # Number of views generated by view selector\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dset_train = ScanObjectNN(data_dir=data_dir, split='train')\n",
    "# dset_test = ScanObjectNN(data_dir=data_dir, split='test')\n",
    "\n",
    "dset_train = ModelNet40(data_dir=data_dir, split='train')\n",
    "dset_test = ModelNet40(data_dir=data_dir, split='test')\n",
    "\n",
    "train_loader = CustomDataLoader(dset_train, batch_size=16, shuffle=True, drop_last=False)\n",
    "test_loader = CustomDataLoader(dset_test, batch_size=16, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9843, 2468)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dset_train), len(dset_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define main components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/pelissier/.cache/torch/hub/pytorch_vision_v0.8.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "# Create backbone multi-view network (ResNet18)\n",
    "mvnetwork = MVNetwork(num_classes=len(dset_train.classes), num_parts=None, mode='cls', net_name='resnet18').cuda()\n",
    "\n",
    "# Create backbone optimizer\n",
    "optimizer = torch.optim.AdamW(mvnetwork.parameters(), lr=0.00001, weight_decay=0.03)\n",
    "\n",
    "# Create view selector\n",
    "mvtn = MVTN(nb_views=nb_views).cuda()\n",
    "\n",
    "# Create optimizer for view selector (In case views are not fixed, otherwise set to None)\n",
    "#mvtn_optimizer = torch.optim.AdamW(mvtn.parameters(), lr=0.0001, weight_decay=0.01)\n",
    "mvtn_optimizer = None\n",
    "\n",
    "# Create multi-view renderer\n",
    "mvrenderer = MVRenderer(nb_views=nb_views, return_mapping=False)\n",
    "\n",
    "# Create loss function for training\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train/test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training\n",
    "# Create a directory with the current date and time\n",
    "current_time = datetime.now().strftime(\"%m-%d_%Hh%Mm%S\")\n",
    "results_dir_current = results_dir+f'results_{current_time}'\n",
    "os.makedirs(results_dir_current, exist_ok=True)\n",
    "os.makedirs(results_dir_current+\"/best\", exist_ok=True)\n",
    "os.makedirs(results_dir_current+\"/by_epoch\", exist_ok=True)\n",
    "\n",
    "# Variables to track the best accuracy\n",
    "best_accuracy = 0.0\n",
    "best_epoch = 0\n",
    "\n",
    "# Lists to store loss and accuracy for plotting\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Dictionary to store training parameters and results\n",
    "training_info = {\n",
    "    'epochs': epochs,\n",
    "    'learning_rate': 0.00001,\n",
    "    'weight_decay': 0.03,\n",
    "    'batch_size': None,  # You can set this based on your train_loader\n",
    "    'train_losses': [],\n",
    "    'train_accuracies': [],\n",
    "    'test_losses': [],\n",
    "    'test_accuracies': [],\n",
    "    'best_accuracy': best_accuracy,\n",
    "    'best_epoch': best_epoch\n",
    "}\n",
    "\n",
    "###############################################################################################\n",
    "for epoch in range(epochs):\n",
    "    #print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "    #print(\"\\nTraining...\")\n",
    "    \n",
    "    running_loss = 0\n",
    "    correct = 0.0\n",
    "    \n",
    "    mvnetwork.train(); mvtn.train(); mvrenderer.train()    \n",
    "    \n",
    "    # Use tqdm to create a progress bar\n",
    "    with tqdm.tqdm(total=len(train_loader), desc=f'Training Epoch {epoch + 1}/{epochs}', unit='batch') as pbar:\n",
    "        for i, (targets, meshes, points) in tqdm.tqdm(enumerate(train_loader)):      \n",
    "            azim, elev, dist = mvtn(points, c_batch_size=len(targets))\n",
    "            rendered_images, _ = mvrenderer(meshes, points, azim=azim, elev=elev, dist=dist)\n",
    "            outputs = mvnetwork(rendered_images)[0]\n",
    "\n",
    "            loss = criterion(outputs, targets.cuda())\n",
    "            running_loss += loss.item()\n",
    "            loss.backward()\n",
    "            correct += (torch.max(outputs, dim=1)[1] == targets.cuda()).to(torch.int32).sum().item()\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if mvtn_optimizer is not None:\n",
    "                mvtn_optimizer.step()\n",
    "                mvtn_optimizer.zero_grad()\n",
    "\n",
    "            # Update tqdm progress bar\n",
    "            pbar.set_postfix({'loss': running_loss / (i + 1), 'accuracy': 100.0 * correct / ((i + 1) * len(targets))})\n",
    "            #if i == len(train_loader)-1:  \n",
    "                #pbar.set_postfix({'loss': running_loss / len(train_loader), 'accuracy': 100.0*correct / len(dset_train)})\n",
    "            pbar.update(1)  # Increment progress bar\n",
    "    \n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    avg_train_accuracy = 100.0 * correct / len(dset_train)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    train_accuracies.append(avg_train_accuracy)\n",
    "        \n",
    "    #print(f\"\\nAverage Training Loss = {(running_loss / len(train_loader)):.5f}. Average Training Accuracy = {(100.0*correct / len(dset_train)):.2f}.\")\n",
    "   \n",
    "    \n",
    "    ############################################\n",
    "    # Validate after each epoch\n",
    "    #print(\"\\nTesting...\")\n",
    "    mvnetwork.eval(); mvtn.eval(); mvrenderer.eval()\n",
    "    running_loss = 0\n",
    "    correct = 0.0\n",
    "    # Use tqdm to create a progress bar\n",
    "    with tqdm.tqdm(total=len(train_loader), desc=f'Testing Epoch {epoch + 1}/{epochs}', unit='batch') as pbar:\n",
    "        for i, (targets, meshes, points) in enumerate(test_loader):\n",
    "            with torch.no_grad():\n",
    "                azim, elev, dist = mvtn(points, c_batch_size=len(targets))\n",
    "                rendered_images, _ = mvrenderer(meshes, points, azim=azim, elev=elev, dist=dist)\n",
    "                outputs = mvnetwork(rendered_images)[0]\n",
    "                \n",
    "                loss = criterion(outputs, targets.cuda())\n",
    "                running_loss += loss.item()\n",
    "                correct += (torch.max(outputs, dim=1)[1] == targets.cuda()).to(torch.int32).sum().item()\n",
    "\n",
    "                # Update tqdm progress bar\n",
    "                #pbar.set_postfix({'loss': running_loss / (i + 1), 'accuracy': 100.0 * correct / ((i + 1) * len(targets))})\n",
    "                pbar.update(1)  # Increment progress bar\n",
    "    \n",
    "    avg_test_loss = running_loss / len(test_loader)\n",
    "    avg_test_accuracy = 100.0 * correct / len(dset_test)\n",
    "    test_losses.append(avg_test_loss)\n",
    "    test_accuracies.append(avg_test_accuracy)\n",
    "    \n",
    "    print(f\"Total Average Test Loss = {(running_loss / len(test_loader)):.5f}.  Average Test Accuracy = {(100.0*correct / len(dset_test)):.2f}.\")\n",
    "    #pbar.set_postfix({'loss': running_loss / len(test_loader), 'accuracy': 100.0*correct / len(dset_test)})\n",
    "    \n",
    "    ############################################\n",
    "    #print(\"\\Saving...\")\n",
    "    if True:\n",
    "        # Save the weights after each epoch\n",
    "        torch.save(mvnetwork.state_dict(), results_dir_current+f'/by_epoch/mvnetwork_epoch_{epoch + 1}.pth')\n",
    "        torch.save(mvtn.state_dict(), results_dir_current+f'/by_epoch/mvtn_epoch_{epoch + 1}.pth')\n",
    "        torch.save(mvrenderer.state_dict(), results_dir_current+f'/by_epoch/mvrenderer_epoch_{epoch + 1}.pth')\n",
    "        \n",
    "        # Save the weights if the current epoch's accuracy is better than the best accuracy\n",
    "        test_accuracy = 100.0 * correct / len(dset_test)\n",
    "        if test_accuracy > best_accuracy:\n",
    "            best_accuracy = test_accuracy\n",
    "            best_epoch = epoch + 1  # Store the best epoch (1-indexed)\n",
    "            \n",
    "            # Save the weights of the best epoch\n",
    "            torch.save(mvnetwork.state_dict(), results_dir_current+f'/best/mvnetwork_best_{epoch+1}.pth')\n",
    "            torch.save(mvtn.state_dict(), results_dir_current+f'/best/mvtn_best_{epoch+1}.pth')\n",
    "            torch.save(mvrenderer.state_dict(), results_dir_current+f'/best/mvrenderer_best_{epoch+1}.pth')\n",
    "            print(f\"Best epoch saved : {epoch+1}, with accuracy: {best_accuracy:.2f}%\")\n",
    "            \n",
    "        # Update training_info with the latest epoch results\n",
    "        training_info['train_losses'].append(avg_train_loss)\n",
    "        training_info['train_accuracies'].append(avg_train_accuracy)\n",
    "        training_info['test_losses'].append(avg_test_loss)\n",
    "        training_info['test_accuracies'].append(avg_test_accuracy)\n",
    "        training_info['best_accuracy'] = best_accuracy\n",
    "        training_info['best_epoch'] = best_epoch\n",
    "\n",
    "###############################################################################################\n",
    "# Save training information to a JSON file\n",
    "with open(results_dir_current+'/training_info.json', 'w') as json_file:\n",
    "    json.dump(training_info, json_file, indent=4)\n",
    "\n",
    "print(\"Training complete! Best epoch:\", best_epoch)\n",
    "\n",
    "# Save the training information with 2 figure\n",
    "save_loss_acc(results_dir_current,train_losses, test_losses, train_accuracies, test_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_train = dset_train.cuda() \n",
    "dset_test = dset_test.cuda()\n",
    "train_loader = CustomDataLoader(dset_train, batch_size=20, shuffle=True, drop_last=False, pin_memory=True)\n",
    "test_loader = CustomDataLoader(dset_test, batch_size=20, shuffle=False, drop_last=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/100:  28%|██▊       | 170/616 [13:31<33:29,  4.51s/batch, loss=2.95, accuracy=29.1] "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import profiler as old_profiler\n",
    "\n",
    "# Set up profiler to analyze one epoch\n",
    "with old_profiler.profile(enabled=True, use_cuda=True) as prof:\n",
    "    for epoch in range(epochs):      \n",
    "        running_loss = 0\n",
    "        correct = 0.0\n",
    "        \n",
    "        mvnetwork.train(); mvtn.train(); mvrenderer.train()    \n",
    "        \n",
    "        # Use tqdm to create a progress bar\n",
    "        with tqdm.tqdm(total=len(train_loader), desc=f'Training Epoch {epoch + 1}/{epochs}', unit='batch') as pbar:\n",
    "            for i, (targets, meshes, points) in tqdm.tqdm(enumerate(train_loader)):  \n",
    "                # Move data to GPU with non-blocking transfer\n",
    "                targets = targets.cuda(non_blocking=True)\n",
    "                points = points.cuda(non_blocking=True)\n",
    "                meshes = meshes.cuda(non_blocking=True)  \n",
    "                  \n",
    "                azim, elev, dist = mvtn(points, c_batch_size=len(targets))\n",
    "                rendered_images, _ = mvrenderer(meshes, points, azim=azim, elev=elev, dist=dist)\n",
    "                outputs = mvnetwork(rendered_images)[0]\n",
    "\n",
    "                #loss = criterion(outputs, targets.cuda())\n",
    "                loss = criterion(outputs, targets)\n",
    "                running_loss += loss.item()\n",
    "                loss.backward()\n",
    "                correct += (torch.max(outputs, dim=1)[1] == targets.cuda()).to(torch.int32).sum().item()\n",
    "                \n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                if mvtn_optimizer is not None:\n",
    "                    mvtn_optimizer.step()\n",
    "                    mvtn_optimizer.zero_grad()\n",
    "\n",
    "                # Update tqdm progress bar\n",
    "                pbar.set_postfix({'loss': running_loss / (i + 1), 'accuracy': 100.0 * correct / ((i + 1) * len(targets))})\n",
    "                pbar.update(1)  # Increment progress bar\n",
    "        \n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        avg_train_accuracy = 100.0 * correct / len(dset_train)\n",
    "        print(f\"Training Loss: {avg_train_loss:.4f}, Accuracy: {avg_train_accuracy:.2f}%\")\n",
    "        \n",
    "        ############################################\n",
    "        # Profiling for one epoch only (this can be disabled after analysis)\n",
    "        if epoch == 0:\n",
    "            break  # Only profile the first epoch\n",
    "            \n",
    "# Print the profiling results after each epoch\n",
    "print(prof.key_averages().table(sort_by=\"self_cpu_time_total\"))          \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = TheModelClass(*args, **kwargs)\n",
    "# model.load_state_dict(torch.load(PATH, weights_only=True))\n",
    "# model.eval()\n",
    "\n",
    "# Assuming you have defined your models (mvnetwork, mvtn, mvrenderer) again\n",
    "mvnetwork.load_state_dict(torch.load(results_dir+f'best/mvnetwork_best.pth', weights_only=True)); mvnetwork.eval()\n",
    "mvtn.load_state_dict(torch.load(results_dir+f'best/mvtn_best.pth', weights_only=True)); mvtn.eval()\n",
    "mvrenderer.load_state_dict(torch.load(results_dir+f'best/mvrenderer_best.pth', weights_only=True)); mvrenderer.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the network\n",
    "print(\"\\n\\nTesting...\")\n",
    "mvnetwork.eval(); mvtn.eval(); mvrenderer.eval()\n",
    "running_loss = 0\n",
    "correct = 0.0\n",
    "# Use tqdm to create a progress bar\n",
    "with tqdm.tqdm(total=len(train_loader), desc=f'Epoch {epoch + 1}/{epochs}', unit='batch') as pbar:\n",
    "    for i, (targets, meshes, points) in enumerate(test_loader):\n",
    "        with torch.no_grad():\n",
    "            start_time = time.time()  # Start timing the batch processing\n",
    "            \n",
    "            azim, elev, dist = mvtn(points, c_batch_size=len(targets))\n",
    "            rendered_images, _ = mvrenderer(meshes, points, azim=azim, elev=elev, dist=dist)\n",
    "            outputs = mvnetwork(rendered_images)[0]\n",
    "            \n",
    "            loss = criterion(outputs, targets.cuda())\n",
    "            running_loss += loss.item()\n",
    "            correct += (torch.max(outputs, dim=1)[1] == targets.cuda()).to(torch.int32).sum().item()\n",
    "\n",
    "            # Update tqdm progress bar\n",
    "            elapsed_time = time.time() - start_time\n",
    "            pbar.set_postfix({'loss': running_loss / (i + 1), 'accuracy': 100.0 * correct / ((i + 1) * len(targets))})\n",
    "            pbar.update(1)  # Increment progress bar\n",
    "            \n",
    "print(f\"\\nTotal Average Test Loss = {(running_loss / len(test_loader)):.5f}.  Average Test Accuracy = {(100.0*correct / len(dset_test)):.2f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mvtorchenv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
