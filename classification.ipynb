{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [MVTorch](https://github.com/ajhamdi/mvtorch) 3D Calssification Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- download common 3D datasets ([ModelNet40](https://mega.nz/file/mm5FhJ7I#jGECWn-QSCLH9LLoxhZzSWnf9LCtCavV12toj9SJKPM), [ScanObjectNN](https://mega.nz/file/ampg2QyT#Exo22r-8jzgCa2MOqoqipd39HVqYKG5iykJ5bovjsuI)) and unzip inside `data` directory.\n",
    "\n",
    "- Conda env : `mvtorchenv1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: ligne 1 : cd: data/: Aucun fichier ou dossier de ce nom\n"
     ]
    }
   ],
   "source": [
    "!cd .. && cd .. && cd data/ \n",
    "# # download ModelNet40 from https://mega.nz/file/mm5FhJ7I#jGECWn-QSCLH9LLoxhZzSWnf9LCtCavV12toj9SJKPM \n",
    "# # download ScanObjectNN from https://mega.nz/file/ampg2QyT#Exo22r-8jzgCa2MOqoqipd39HVqYKG5iykJ5bovjsuI \n",
    "\n",
    "# sudo rmmod nvidia_uvm\n",
    "# sudo modprobe nvidia_uvm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depenenancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mpelissi/anaconda3/envs/mvtorchenv1/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "from mvtorch.data import ScanObjectNN, CustomDataLoader, ModelNet40\n",
    "from mvtorch.networks import MVNetwork\n",
    "from mvtorch.view_selector import MVTN\n",
    "from mvtorch.mvrenderer import MVRenderer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_to_Dataset = \"/home/pelissier/These-ATER/Papier_international3/Dataset/\"\n",
    "path_to_Dataset = \"/home/mpelissi/Dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir= path_to_Dataset+'ModelNet40'#+'ScanObjectNN' # specifiy where did you put the data rel\n",
    "nb_views = 12 # Number of views generated by view selector\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dset_train = ScanObjectNN(data_dir=data_dir, split='train')\n",
    "# dset_test = ScanObjectNN(data_dir=data_dir, split='test')\n",
    "\n",
    "dset_train = ModelNet40(data_dir=data_dir, split='train')\n",
    "dset_test = ModelNet40(data_dir=data_dir, split='test')\n",
    "\n",
    "train_loader = CustomDataLoader(dset_train, batch_size=20, shuffle=True, drop_last=False)\n",
    "test_loader = CustomDataLoader(dset_test, batch_size=20, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define main components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/mpelissi/.cache/torch/hub/pytorch_vision_v0.8.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "# Create backbone multi-view network (ResNet18)\n",
    "mvnetwork = MVNetwork(num_classes=len(dset_train.classes), num_parts=None, mode='cls', net_name='resnet18').cuda()\n",
    "\n",
    "# Create backbone optimizer\n",
    "optimizer = torch.optim.AdamW(mvnetwork.parameters(), lr=0.00001, weight_decay=0.03)\n",
    "\n",
    "# Create view selector\n",
    "mvtn = MVTN(nb_views=nb_views).cuda()\n",
    "\n",
    "# Create optimizer for view selector (In case views are not fixed, otherwise set to None)\n",
    "#mvtn_optimizer = torch.optim.AdamW(mvtn.parameters(), lr=0.0001, weight_decay=0.01)\n",
    "mvtn_optimizer = None\n",
    "\n",
    "# Create multi-view renderer\n",
    "mvrenderer = MVRenderer(nb_views=nb_views, return_mapping=False)\n",
    "\n",
    "# Create loss function for training\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train/test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/2\n",
      "\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 12/493 [01:09<41:18,  5.15s/batch, loss=3.69, accuracy=4.58]"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import time \n",
    "\n",
    "for epoch in range(epochs):\n",
    "    correct = 0.0\n",
    "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "    print(\"\\nTraining...\")\n",
    "    \n",
    "    mvnetwork.train(); mvtn.train(); mvrenderer.train()\n",
    "    \n",
    "    running_loss = 0\n",
    "    # Use tqdm to create a progress bar\n",
    "    with tqdm.tqdm(total=len(train_loader), desc=f'Epoch {epoch + 1}/{epochs}', unit='batch') as pbar:\n",
    "        for i, (targets, meshes, points) in tqdm.tqdm(enumerate(train_loader)):\n",
    "            start_time = time.time()  # Start timing the batch processing\n",
    "            \n",
    "            azim, elev, dist = mvtn(points, c_batch_size=len(targets))\n",
    "            rendered_images, _ = mvrenderer(meshes, points, azim=azim, elev=elev, dist=dist)\n",
    "            outputs = mvnetwork(rendered_images)[0]\n",
    "\n",
    "            loss = criterion(outputs, targets.cuda())\n",
    "            running_loss += loss.item()\n",
    "            loss.backward()\n",
    "            correct += (torch.max(outputs, dim=1)[1] == targets.cuda()).to(torch.int32).sum().item()\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if mvtn_optimizer is not None:\n",
    "                mvtn_optimizer.step()\n",
    "                mvtn_optimizer.zero_grad()\n",
    "\n",
    "            # Update tqdm progress bar\n",
    "            elapsed_time = time.time() - start_time\n",
    "            pbar.set_postfix({'loss': running_loss / (i + 1), 'accuracy': 100.0 * correct / ((i + 1) * len(targets))})\n",
    "            pbar.update(1)  # Increment progress bar\n",
    "            \n",
    "                \n",
    "    print(f\"\\nAverage Training Loss = {(running_loss / len(train_loader)):.5f}. Average Training Accuracy = {(100.0*correct / len(dset_train)):.2f}.\")\n",
    "\n",
    "    # Test the network\n",
    "    print(\"\\n\\nTesting...\")\n",
    "    mvnetwork.eval(); mvtn.eval(); mvrenderer.eval()\n",
    "    running_loss = 0\n",
    "    correct = 0.0\n",
    "    # Use tqdm to create a progress bar\n",
    "    with tqdm.tqdm(total=len(train_loader), desc=f'Epoch {epoch + 1}/{epochs}', unit='batch') as pbar:\n",
    "        for i, (targets, meshes, points) in enumerate(test_loader):\n",
    "            with torch.no_grad():\n",
    "                start_time = time.time()  # Start timing the batch processing\n",
    "                \n",
    "                azim, elev, dist = mvtn(points, c_batch_size=len(targets))\n",
    "                rendered_images, _ = mvrenderer(meshes, points, azim=azim, elev=elev, dist=dist)\n",
    "                outputs = mvnetwork(rendered_images)[0]\n",
    "                \n",
    "                loss = criterion(outputs, targets.cuda())\n",
    "                running_loss += loss.item()\n",
    "                correct += (torch.max(outputs, dim=1)[1] == targets.cuda()).to(torch.int32).sum().item()\n",
    "\n",
    "                # Update tqdm progress bar\n",
    "                elapsed_time = time.time() - start_time\n",
    "                pbar.set_postfix({'loss': running_loss / (i + 1), 'accuracy': 100.0 * correct / ((i + 1) * len(targets))})\n",
    "                pbar.update(1)  # Increment progress bar\n",
    "                \n",
    "    print(f\"\\nTotal Average Test Loss = {(running_loss / len(test_loader)):.5f}.  Average Test Accuracy = {(100.0*correct / len(dset_test)):.2f}.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mvtorchenv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
