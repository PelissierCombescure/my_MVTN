{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [MVTorch](https://github.com/ajhamdi/mvtorch) 3D Calssification Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- download common 3D datasets ([ModelNet40](https://mega.nz/file/mm5FhJ7I#jGECWn-QSCLH9LLoxhZzSWnf9LCtCavV12toj9SJKPM), [ScanObjectNN](https://mega.nz/file/ampg2QyT#Exo22r-8jzgCa2MOqoqipd39HVqYKG5iykJ5bovjsuI)) and unzip inside `data` directory.\n",
    "\n",
    "- Conda env : `mvtorchenv1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: ligne 1 : cd: data/: Aucun fichier ou dossier de ce nom\n"
     ]
    }
   ],
   "source": [
    "!cd .. && cd .. && cd data/ \n",
    "# # download ModelNet40 from https://mega.nz/file/mm5FhJ7I#jGECWn-QSCLH9LLoxhZzSWnf9LCtCavV12toj9SJKPM \n",
    "# # download ScanObjectNN from https://mega.nz/file/ampg2QyT#Exo22r-8jzgCa2MOqoqipd39HVqYKG5iykJ5bovjsuI \n",
    "\n",
    "# sudo rmmod nvidia_uvm\n",
    "# sudo modprobe nvidia_uvm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depenenancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mpelissi/anaconda3/envs/MVTN_env3/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import tqdm\n",
    "import time \n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import subprocess\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "from mvtorch.data import ScanObjectNN, CustomDataLoader, ModelNet40\n",
    "from mvtorch.networks import MVNetwork\n",
    "from mvtorch.view_selector import MVTN\n",
    "from mvtorch.mvrenderer import MVRenderer\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the command and capture the output\n",
    "current_dir = subprocess.check_output('pwd', shell=True).decode('utf-8').strip()\n",
    "Papier_inter3_dir = os.path.abspath(os.path.join(current_dir, \"../../\"))\n",
    "\n",
    "path_to_Dataset = Papier_inter3_dir+\"/Dataset/\"\n",
    "results_dir = current_dir+\"/results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/mpelissi/MVTN/my_MVTN', '/home/mpelissi')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir, Papier_inter3_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir= path_to_Dataset+'ModelNet40'#+'ScanObjectNN' # specifiy where did you put the data rel\n",
    "nb_views = 8 # Number of views generated by view selector\n",
    "epochs = 3\n",
    "bs = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dset_train = ScanObjectNN(data_dir=data_dir, split='train')\n",
    "# dset_test = ScanObjectNN(data_dir=data_dir, split='test')\n",
    "\n",
    "dset_train = ModelNet40(data_dir=data_dir, split='train')\n",
    "dset_test = ModelNet40(data_dir=data_dir, split='test')\n",
    "\n",
    "train_loader = CustomDataLoader(dset_train, batch_size=bs, shuffle=True, drop_last=False)\n",
    "test_loader = CustomDataLoader(dset_test, batch_size=bs, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mvtorch.data.ModelNet40 at 0x7559ec0dbbe0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dset_train), len(dset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define main components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "# Create backbone multi-view network (ResNet18)\n",
    "mvnetwork = MVNetwork(num_classes=len(dset_train.classes), num_parts=None, mode='cls', net_name='resnet18').cuda()\n",
    "\n",
    "# Create backbone optimizer\n",
    "optimizer = torch.optim.AdamW(mvnetwork.parameters(), lr=0.00001, weight_decay=0.03)\n",
    "\n",
    "# Create view selector\n",
    "mvtn = MVTN(nb_views=nb_views).cuda()\n",
    "\n",
    "# Create optimizer for view selector (In case views are not fixed, otherwise set to None)\n",
    "#mvtn_optimizer = torch.optim.AdamW(mvtn.parameters(), lr=0.0001, weight_decay=0.01)\n",
    "mvtn_optimizer = None\n",
    "\n",
    "# Create multi-view renderer\n",
    "mvrenderer = MVRenderer(nb_views=nb_views, return_mapping=False)\n",
    "\n",
    "# Create loss function for training\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train/test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training\n",
    "# Create a directory with the current date and time\n",
    "current_time = datetime.now().strftime(\"%m-%d_%Hh%Mm%S\")\n",
    "results_dir_current = results_dir+f'results_{current_time}'\n",
    "os.makedirs(results_dir_current, exist_ok=True)\n",
    "os.makedirs(results_dir_current+\"/best\", exist_ok=True)\n",
    "os.makedirs(results_dir_current+\"/by_epoch\", exist_ok=True)\n",
    "\n",
    "# Variables to track the best accuracy\n",
    "best_accuracy = 0.0\n",
    "best_epoch = 0\n",
    "\n",
    "# Lists to store loss and accuracy for plotting\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Dictionary to store training parameters and results\n",
    "training_info = {\n",
    "    'nb_views': nb_views,\n",
    "    'epochs': epochs,\n",
    "    'learning_rate': 0.00001,\n",
    "    'weight_decay': 0.03,\n",
    "    'batch_size': bs,\n",
    "    'batch_size': None,  # You can set this based on your train_loader\n",
    "    'train_losses': [],\n",
    "    'train_accuracies': [],\n",
    "    'test_losses': [],\n",
    "    'test_accuracies': [],\n",
    "    'best_accuracy': best_accuracy,\n",
    "    'best_epoch': best_epoch\n",
    "}\n",
    "\n",
    "###############################################################################################\n",
    "for epoch in range(epochs):\n",
    "    #break\n",
    "    #print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "    #print(\"\\nTraining...\")\n",
    "    \n",
    "    running_loss = 0\n",
    "    correct = 0.0\n",
    "    \n",
    "    mvnetwork.train(); mvtn.train(); mvrenderer.train()    \n",
    "    \n",
    "    for i, (targets, meshes, points) in enumerate(train_loader):      \n",
    "        azim, elev, dist = mvtn(points, c_batch_size=len(targets))\n",
    "        rendered_images, _ = mvrenderer(meshes, points, azim=azim, elev=elev, dist=dist)\n",
    "        outputs = mvnetwork(rendered_images)[0]\n",
    "\n",
    "        loss = criterion(outputs, targets.cuda())\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "        correct += (torch.max(outputs, dim=1)[1] == targets.cuda()).to(torch.int32).sum().item()\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if mvtn_optimizer is not None:\n",
    "            mvtn_optimizer.step()\n",
    "            mvtn_optimizer.zero_grad()\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader) # diviser par le nombre de batch\n",
    "    avg_train_accuracy = 100.0 * correct / len(dset_train) # diviser par le nombre total de données\n",
    "    train_losses.append(avg_train_loss)\n",
    "    train_accuracies.append(avg_train_accuracy)\n",
    "        \n",
    "    print(f\"\\n[Epoch {epoch + 1}/{epochs}]\")\n",
    "    print(f\"Training - Loss: {avg_train_loss:.5f}, Accuracy: {avg_train_accuracy:.2f}%\")\n",
    "      \n",
    "    mvnetwork.eval()\n",
    "    mvtn.eval()\n",
    "    mvrenderer.eval()\n",
    "    running_loss = 0\n",
    "    correct_test = 0.0\n",
    "    for i, (targets, meshes, points) in enumerate(test_loader):\n",
    "        with torch.no_grad():\n",
    "            azim, elev, dist = mvtn(points, c_batch_size=len(targets))\n",
    "            rendered_images, _ = mvrenderer(meshes, points, azim=azim, elev=elev, dist=dist)\n",
    "            outputs = mvnetwork(rendered_images)[0]\n",
    "\n",
    "            loss = criterion(outputs, targets.cuda())\n",
    "            running_loss += loss.item()\n",
    "            correct_test += (torch.max(outputs, dim=1)[1] == targets.cuda()).to(torch.int32).sum().item()\n",
    "\n",
    "\n",
    "    avg_test_loss = running_loss / len(test_loader) # diviser par le nombre de batch\n",
    "    avg_test_accuracy = 100.0 * correct_test / len(dset_test) # diviser par le nombre total de données\n",
    "    test_losses.append(avg_test_loss)\n",
    "    test_losses.append(avg_test_accuracy)\n",
    "        \n",
    "    print(f\"\\n[Epoch {epoch + 1}/{epochs}]\")\n",
    "    print(f\"Testing - Loss: {avg_test_loss:.5f}, Accuracy: {avg_test_accuracy:.2f}%\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Opitmize code 1/3\n",
    "train_loader = CustomDataLoader(dset_train, batch_size=20, shuffle=True, drop_last=False, pin_memory=True)\n",
    "test_loader = CustomDataLoader(dset_test, batch_size=20, shuffle=False, drop_last=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import profiler as old_profiler\n",
    "\n",
    "for epoch in range(epochs):         \n",
    "    # Set up profiler to analyze one epoch\n",
    "    with old_profiler.profile(enabled=True, use_cuda=True) as prof: \n",
    "         # Training loop\n",
    "        running_loss = 0\n",
    "        correct = 0.0        \n",
    "        mvnetwork.train(); mvtn.train(); mvrenderer.train()    \n",
    "        \n",
    "        # Use tqdm to create a progress bar\n",
    "        with tqdm.tqdm(total=len(train_loader), desc=f'Training Epoch {epoch + 1}/{epochs}', unit='batch') as pbar:\n",
    "            for i, (targets, meshes, points) in tqdm.tqdm(enumerate(train_loader)):  \n",
    "                ## Opitmize code 2/3 \n",
    "                # Move data to GPU with non-blocking transfer\n",
    "                # targets = targets.cuda(non_blocking=True)\n",
    "                # points = points.cuda(non_blocking=True)\n",
    "                # meshes = torch.tensor(meshes).cuda(non_blocking=True)\n",
    "                                  \n",
    "                azim, elev, dist = mvtn(points, c_batch_size=len(targets))\n",
    "                rendered_images, _ = mvrenderer(meshes, points, azim=azim, elev=elev, dist=dist)\n",
    "                outputs = mvnetwork(rendered_images.cuda())[0]\n",
    "\n",
    "                loss = criterion(outputs, targets.cuda())\n",
    "                #loss = criterion(outputs, targets) ## Opitmize code 3/3\n",
    "                running_loss += loss.item()\n",
    "                loss.backward()\n",
    "                correct += (torch.max(outputs, dim=1)[1] == targets.cuda()).to(torch.int32).sum().item()\n",
    "                \n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                if mvtn_optimizer is not None:\n",
    "                    mvtn_optimizer.step()\n",
    "                    mvtn_optimizer.zero_grad()\n",
    "\n",
    "                # Update tqdm progress bar\n",
    "                pbar.set_postfix({'loss': running_loss / (i + 1), 'accuracy': 100.0 * correct / ((i + 1) * len(targets))})\n",
    "                pbar.update(1)  # Increment progress bar\n",
    "        \n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        avg_train_accuracy = 100.0 * correct / len(dset_train)\n",
    "        print(f\"Training Loss: {avg_train_loss:.4f}, Accuracy: {avg_train_accuracy:.2f}%\")\n",
    "        \n",
    "        ############################################\n",
    "       \n",
    "    # Print the profiling results after each epoch\n",
    "    print('Profiling results:')\n",
    "    print(prof.key_averages().table(sort_by=\"self_cpu_time_total\"))          \n",
    "\n",
    "    if epoch == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = TheModelClass(*args, **kwargs)\n",
    "# model.load_state_dict(torch.load(PATH, weights_only=True))\n",
    "# model.eval()\n",
    "\n",
    "# Assuming you have defined your models (mvnetwork, mvtn, mvrenderer) again\n",
    "mvnetwork.load_state_dict(torch.load(results_dir+f'best/mvnetwork_best.pth', weights_only=True)); mvnetwork.eval()\n",
    "mvtn.load_state_dict(torch.load(results_dir+f'best/mvtn_best.pth', weights_only=True)); mvtn.eval()\n",
    "mvrenderer.load_state_dict(torch.load(results_dir+f'best/mvrenderer_best.pth', weights_only=True)); mvrenderer.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the network\n",
    "print(\"\\n\\nTesting...\")\n",
    "mvnetwork.eval(); mvtn.eval(); mvrenderer.eval()\n",
    "running_loss = 0\n",
    "correct = 0.0\n",
    "# Use tqdm to create a progress bar\n",
    "with tqdm.tqdm(total=len(train_loader), desc=f'Epoch {epoch + 1}/{epochs}', unit='batch') as pbar:\n",
    "    for i, (targets, meshes, points) in enumerate(test_loader):\n",
    "        with torch.no_grad():\n",
    "            start_time = time.time()  # Start timing the batch processing\n",
    "            \n",
    "            azim, elev, dist = mvtn(points, c_batch_size=len(targets))\n",
    "            rendered_images, _ = mvrenderer(meshes, points, azim=azim, elev=elev, dist=dist)\n",
    "            outputs = mvnetwork(rendered_images)[0]\n",
    "            \n",
    "            loss = criterion(outputs, targets.cuda())\n",
    "            running_loss += loss.item()\n",
    "            correct += (torch.max(outputs, dim=1)[1] == targets.cuda()).to(torch.int32).sum().item()\n",
    "\n",
    "            # Update tqdm progress bar\n",
    "            elapsed_time = time.time() - start_time\n",
    "            pbar.set_postfix({'loss': running_loss / (i + 1), 'accuracy': 100.0 * correct / ((i + 1) * len(targets))})\n",
    "            pbar.update(1)  # Increment progress bar\n",
    "            \n",
    "print(f\"\\nTotal Average Test Loss = {(running_loss / len(test_loader)):.5f}.  Average Test Accuracy = {(100.0*correct / len(dset_test)):.2f}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MVTN_env3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
