{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [MVTorch](https://github.com/ajhamdi/mvtorch) 3D Calssification Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- download common 3D datasets ([ModelNet40](https://mega.nz/file/mm5FhJ7I#jGECWn-QSCLH9LLoxhZzSWnf9LCtCavV12toj9SJKPM), [ScanObjectNN](https://mega.nz/file/ampg2QyT#Exo22r-8jzgCa2MOqoqipd39HVqYKG5iykJ5bovjsuI)) and unzip inside `data` directory.\n",
    "\n",
    "- Conda env : `mvtorchenv1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd .. && cd .. && cd data/ \n",
    "# # download ModelNet40 from https://mega.nz/file/mm5FhJ7I#jGECWn-QSCLH9LLoxhZzSWnf9LCtCavV12toj9SJKPM \n",
    "# # download ScanObjectNN from https://mega.nz/file/ampg2QyT#Exo22r-8jzgCa2MOqoqipd39HVqYKG5iykJ5bovjsuI \n",
    "\n",
    "# sudo rmmod nvidia_uvm\n",
    "# sudo modprobe nvidia_uvm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depenenancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "from mvtorch.data import ScanObjectNN, CustomDataLoader, ModelNet40\n",
    "from mvtorch.networks import MVNetwork\n",
    "from mvtorch.view_selector import MVTN\n",
    "from mvtorch.mvrenderer import MVRenderer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_to_Dataset = \"/home/pelissier/These-ATER/Papier_international3/Dataset/\"\n",
    "path_to_Dataset = \"/home/mpelissi/Dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir= path_to_Dataset+'ModelNet40'#+'ScanObjectNN' # specifiy where did you put the data rel\n",
    "nb_views = 12 # Number of views generated by view selector\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dset_train = ScanObjectNN(data_dir=data_dir, split='train')\n",
    "# dset_test = ScanObjectNN(data_dir=data_dir, split='test')\n",
    "\n",
    "dset_train = ModelNet40(data_dir=data_dir, split='train')\n",
    "dset_test = ModelNet40(data_dir=data_dir, split='test')\n",
    "\n",
    "train_loader = CustomDataLoader(dset_train, batch_size=20, shuffle=True, drop_last=False)\n",
    "test_loader = CustomDataLoader(dset_test, batch_size=20, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define main components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "# Create backbone multi-view network (ResNet18)\n",
    "mvnetwork = MVNetwork(num_classes=len(dset_train.classes), num_parts=None, mode='cls', net_name='resnet18').cuda()\n",
    "\n",
    "# Create backbone optimizer\n",
    "optimizer = torch.optim.AdamW(mvnetwork.parameters(), lr=0.00001, weight_decay=0.03)\n",
    "\n",
    "# Create view selector\n",
    "mvtn = MVTN(nb_views=nb_views).cuda()\n",
    "\n",
    "# Create optimizer for view selector (In case views are not fixed, otherwise set to None)\n",
    "#mvtn_optimizer = torch.optim.AdamW(mvtn.parameters(), lr=0.0001, weight_decay=0.01)\n",
    "mvtn_optimizer = None\n",
    "\n",
    "# Create multi-view renderer\n",
    "mvrenderer = MVRenderer(nb_views=nb_views, return_mapping=False)\n",
    "\n",
    "# Create loss function for training\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train/test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "for epoch in range(epochs):\n",
    "    correct = 0.0\n",
    "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "    print(\"\\n\\nTraining...\")\n",
    "    mvnetwork.train()\n",
    "    mvtn.train()\n",
    "    mvrenderer.train()\n",
    "    running_loss = 0\n",
    "    for i, (targets, meshes, points) in tqdm.tqdm(enumerate(train_loader)):\n",
    "        azim, elev, dist = mvtn(points, c_batch_size=len(targets))\n",
    "        rendered_images, _ = mvrenderer(meshes, points, azim=azim, elev=elev, dist=dist)\n",
    "        outputs = mvnetwork(rendered_images)[0]\n",
    "\n",
    "        loss = criterion(outputs, targets.cuda())\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "        correct += (torch.max(outputs, dim=1)[1] == targets.cuda()).to(torch.int32).sum().item()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if mvtn_optimizer is not None:\n",
    "            mvtn_optimizer.step()\n",
    "            mvtn_optimizer.zero_grad()\n",
    "        \n",
    "        if (i + 1) % int(len(train_loader) * 0.25) == 0:\n",
    "            print(f\"\\tBatch {i + 1}/{len(train_loader)}: Current Average Training Loss = {(running_loss / (i + 1)):.5f}\")\n",
    "    print(f\"\\nAverage Training Loss = {(running_loss / len(train_loader)):.5f}. Average Training Accuracy = {(100.0*correct / len(dset_train)):.2f}.\")\n",
    "\n",
    "    print(\"\\n\\nTesting...\")\n",
    "    mvnetwork.eval()\n",
    "    mvtn.eval()\n",
    "    mvrenderer.eval()\n",
    "    running_loss = 0\n",
    "    correct = 0.0\n",
    "    for i, (targets, meshes, points) in enumerate(test_loader):\n",
    "        with torch.no_grad():\n",
    "            azim, elev, dist = mvtn(points, c_batch_size=len(targets))\n",
    "            rendered_images, _ = mvrenderer(meshes, points, azim=azim, elev=elev, dist=dist)\n",
    "            outputs = mvnetwork(rendered_images)[0]\n",
    "            \n",
    "            loss = criterion(outputs, targets.cuda())\n",
    "            running_loss += loss.item()\n",
    "            correct += (torch.max(outputs, dim=1)[1] == targets.cuda()).to(torch.int32).sum().item()\n",
    "\n",
    "            if (i + 1) % int(len(test_loader) * 0.25) == 0:\n",
    "                print(f\"\\tBatch {i + 1}/{len(test_loader)}: Current Average Test Loss = {(running_loss / (i + 1)):.5f}\")\n",
    "    print(f\"\\nTotal Average Test Loss = {(running_loss / len(test_loader)):.5f}.  Average Test Accuracy = {(100.0*correct / len(dset_test)):.2f}.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mvtorchenv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
