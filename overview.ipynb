{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mpelissi/anaconda3/envs/MVTN_env3/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mvtorch.data import ModelNet40, CustomDataLoader\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import trimesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gpu_name</th>\n",
       "      <th>folder_name</th>\n",
       "      <th>nb_views</th>\n",
       "      <th>epochs</th>\n",
       "      <th>patience</th>\n",
       "      <th>min_delta</th>\n",
       "      <th>data_dir</th>\n",
       "      <th>category</th>\n",
       "      <th>log_suffix</th>\n",
       "      <th>epoch_earlystop</th>\n",
       "      <th>...</th>\n",
       "      <th>lr_opti</th>\n",
       "      <th>lr_mvtn_optimizer</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>pc_rendering</th>\n",
       "      <th>simplified_mesh</th>\n",
       "      <th>canonical_dist</th>\n",
       "      <th>best_accuracy</th>\n",
       "      <th>best_epoch</th>\n",
       "      <th>simplified_mesh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [gpu_name, folder_name, nb_views, epochs, patience, min_delta, data_dir, category, log_suffix, epoch_earlystop, views_config, opti_mvtn, lr_opti, lr_mvtn_optimizer, weight_decay, batch_size, pc_rendering, simplified_mesh, canonical_dist, best_accuracy, best_epoch, simplified_mesh]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save an example DataFrame to a CSV file\n",
    "with open(\"/home/mpelissi/MVTN/my_MVTN/results/train/results_06-12_17h10m05-Quadro RTX 5000/training_info.json\", 'r') as f:\n",
    "    data_json = json.load(f)\n",
    "columns = [key for key in data_json.keys() if 'test' not in key and 'train' not in key] + ['simplified_mesh']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "df.to_csv('/home/mpelissi/MVTN/my_MVTN/results/train/overview.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "train_folder = '/home/mpelissi/MVTN/my_MVTN/results/train'\n",
    "json_files = glob.glob(os.path.join(train_folder, '**', 'training_info.json'), recursive=True)\n",
    "print(len(json_files))\n",
    "\n",
    "for l, json_file in enumerate(json_files):\n",
    "    if '06-04' not in json_file:\n",
    "        with open(json_file, 'r') as f:\n",
    "            data_json = json.load(f)\n",
    "            values = []\n",
    "            for c in columns:\n",
    "                if c not in data_json:\n",
    "                    if c == 'pc_rendering': values.append('True')\n",
    "                    elif c == 'canonical_dist' : values.append(1.1)\n",
    "                    elif c == 'simplified_mesh': values.append('False')\n",
    "                    else:\n",
    "                        values.append('not saved')\n",
    "                        \n",
    "                elif c == 'lr_opti':\n",
    "                    values.append(str(data_json[c]))\n",
    "                elif data_json[c] is None:\n",
    "                    values.append('None')\n",
    "                else:       \n",
    "                    values.append(data_json[c])\n",
    "            df.loc[l] = values\n",
    "df.to_csv('/home/mpelissi/MVTN/my_MVTN/results/train/overview.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "def count_vertices_in_obj(filepath):\n",
    "    \"\"\"\n",
    "    Counts the number of vertices ('v ' lines) in an OBJ file.\n",
    "    \"\"\"\n",
    "    num_vertices = 0\n",
    "    num_faces = 0\n",
    "    try:\n",
    "        with open(filepath, 'r') as f:\n",
    "            for line in f:\n",
    "                if line.startswith('v '):\n",
    "                    num_vertices += 1\n",
    "                elif line.startswith('f '):\n",
    "                    num_faces += 1\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not read {filepath}. Error: {e}\")\n",
    "        return None\n",
    "    return num_vertices, num_faces\n",
    "\n",
    "def generate_vertex_histogram(data_dir, output_filename=\"mesh_histogram.png\"):\n",
    "    \"\"\"\n",
    "    Generates a histogram of vertex counts for all .obj files in a directory.\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): The path to the directory containing .obj files.\n",
    "        output_filename (str): The filename for the saved histogram image.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(data_dir):\n",
    "        print(f\"Error: Directory not found at {data_dir}\")\n",
    "        return\n",
    "\n",
    "    vertex_counts = []\n",
    "    faces_counts = []\n",
    "    obj_files_found = 0\n",
    "\n",
    "    print(f\"Scanning directory: {data_dir} for .obj files...\")\n",
    "    # Walk through the directory to find all .obj files\n",
    "    for root, _, files in os.walk(data_dir):\n",
    "        for file in files:\n",
    "            if file.lower().endswith('.obj') and 'SMPLER' in file:\n",
    "                obj_files_found += 1\n",
    "                filepath = os.path.join(root, file)\n",
    "                # print(f\"Found OBJ: {filepath}\") # Uncomment for debugging if needed\n",
    "                num_vertices, num_faces = count_vertices_in_obj(filepath)\n",
    "                if num_vertices is not None:\n",
    "                    vertex_counts.append(num_vertices)\n",
    "                if num_faces is not None:                    \n",
    "                    faces_counts.append(num_faces)\n",
    "\n",
    "    if not vertex_counts:\n",
    "        print(f\"No .obj files found or no vertices counted in {data_dir}. Cannot generate histogram.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {obj_files_found} .obj files and extracted vertex counts for {len(vertex_counts)} of them.\")\n",
    "\n",
    "    # Convert to numpy array for easier plotting\n",
    "    vertex_counts = np.array(vertex_counts)\n",
    "    faces_counts = np.array(faces_counts)\n",
    "\n",
    "    # --- Plotting the histogram ---\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    \n",
    "    # Determine bins for the histogram\n",
    "    # Option 1: Fixed number of bins (e.g., 50 bins)\n",
    "    # plt.hist(vertex_counts, bins=50, color='skyblue', edgecolor='black')\n",
    "    \n",
    "    # Option 2: Dynamically calculate bins based on data range\n",
    "    # You might want to adjust these based on your data distribution\n",
    "    min_verts = vertex_counts.min()\n",
    "    max_verts = vertex_counts.max()\n",
    "    min_faces = faces_counts.min()\n",
    "    max_faces = faces_counts.max()\n",
    "    # A common approach is to use a logarithmic scale for bins if counts vary widely\n",
    "    # Or, if data is concentrated, use a finer linear binning\n",
    "    \n",
    "    # Let's try a default of auto-binning which often works well\n",
    "    plt.hist(vertex_counts, bins='auto', color='#3498DB', edgecolor='#2C3E50', alpha=0.8) # Using a nice blue color\n",
    "    plt.title('Histogram of Mesh Vertex Counts in ModelNet40 Dataset', fontsize=16)\n",
    "    plt.xlabel('Number of Vertices', fontsize=12)\n",
    "    plt.ylabel('Frequency (Number of Meshes)', fontsize=12)\n",
    "    plt.grid(axis='y', alpha=0.75, linestyle='--')\n",
    "    plt.yscale('linear') # Can change to 'log' if many small values and few large ones for better visualization\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the histogram\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    plt.savefig(output_filename.replace('.png', \"_vertices.png\"), dpi=300, bbox_inches='tight')\n",
    "    plt.hist(faces_counts, bins='auto', color='red', edgecolor='#2C3E50', alpha=0.8) # Using a nice blue color\n",
    "    plt.title('Histogram of Mesh Faces Counts in ModelNet40 Dataset', fontsize=16)\n",
    "    plt.xlabel('Number of Faces', fontsize=12)\n",
    "    plt.ylabel('Frequency (Number of Meshes)', fontsize=12)\n",
    "    plt.grid(axis='y', alpha=0.75, linestyle='--')\n",
    "    plt.yscale('linear'); plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the histogram\n",
    "    plt.savefig(output_filename.replace('.png', \"_faces.png\"), dpi=300, bbox_inches='tight')\n",
    "    return vertex_counts, faces_counts\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    modelnet_dir = \"/home/mpelissi/Dataset/ModelNet40/\"\n",
    "    vertex_counts, faces_counts = generate_vertex_histogram(modelnet_dir, \"modelnet40_vertex_histogram.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vertex_counts), max(vertex_counts), min(vertex_counts), np.mean(vertex_counts), np.std(vertex_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vertex_counts), max(vertex_counts), min(vertex_counts), np.mean(vertex_counts), np.std(vertex_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threeobject = trimesh.load(\"/home/mpelissi/Dataset/ModelNet40//stairs/train/stairs_0110_SMPLER.obj\")\n",
    "print(threeobject.vertices.shape, threeobject.faces.shape)\n",
    "threeobject_simplified = threeobject.simplify_quadric_decimation(percent=0.5)\n",
    "print(threeobject_simplified.vertices.shape, threeobject_simplified.faces.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MVTN_env3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
